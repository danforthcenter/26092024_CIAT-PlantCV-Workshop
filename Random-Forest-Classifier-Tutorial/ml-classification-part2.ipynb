{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-witness",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-wound",
   "metadata": {},
   "source": [
    "## Locate filepaths of all data saved out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-sierra",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get current working directory (the file path where is this notebook located?)\n",
    "path = os.getcwd() \n",
    "\n",
    "# Any file with .csv file extension will get stored into list of csv filename\n",
    "csv_filenames = glob.glob(os.path.join(path, \"*.csv\"))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-separate",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do you have as many data filenames as expected? \n",
    "csv_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-slave",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define empty list for storing our various dataframes \n",
    "data_list = []\n",
    "\n",
    "# loop over the list of csv files\n",
    "for f in csv_filenames:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    # Append to the list called data_list \n",
    "    data_list.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-illustration",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate (combine) all dataframes into a single dataframe \n",
    "all_data = pd.concat(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-adapter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data wrangling steps\n",
    "# a.k.a. change the shape (structure) of the dataframe into compatible format for next steps\n",
    "\n",
    "# Filter the traits kept\n",
    "seed_features = all_data[all_data['trait'].isin(['area', 'convex_hull_area', 'solidity',\n",
    "                                                   'perimeter', 'width', 'height', 'ellipse_major_axis',\n",
    "                                                   'ellipse_minor_axis', 'ellipse_eccentricity',\n",
    "                                                   'hue_circular_mean', 'hue_median'])]\n",
    "# Pivot (Transform) the dataframe from \"long\" format to \"wide\"\n",
    "seed_features_wide = pd.pivot(seed_features, index='sample', columns=\"trait\", values=\"value\")\n",
    "# Cast (change data type) to numpy array \n",
    "np_features = seed_features_wide.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-context",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Investigate the formatted data \n",
    "seed_features_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-florida",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract list of traits\n",
    "trait_list = seed_features_wide.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-saturn",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect list of labels \n",
    "labels = []\n",
    "for name in trait_list:\n",
    "    seed_num = name.split(\"_\")[0]\n",
    "    labels.append(seed_num)\n",
    "    \n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-portrait",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-generator",
   "metadata": {},
   "source": [
    "Feed the trait data into the Random Forest Classifier. Giving the function data to train a model on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-facing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = np_features\n",
    "y_train = labels\n",
    "\n",
    "feature_names = list(seed_features_wide.columns)\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-albert",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract feature importances from the model created, and standard deviations for each\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-earth",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a plot to display \n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-exchange",
   "metadata": {},
   "source": [
    "# STOP ðŸ›‘  HERE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-dominican",
   "metadata": {},
   "source": [
    "Below this point is an example of how to use a trained classifier on unlabeled data, getting collected from a seed scatter image with mixed seed types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-times",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-spank",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-burst",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-wedding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outside-contamination",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "# Take a bean scatter image and extract traits \n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn debugging images on \n",
    "pcv.params.debug = \"plot\"\n",
    "# Read image\n",
    "\n",
    "# Inputs:\n",
    "#   filename - Image file to be read in \n",
    "#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "\n",
    "# Read in bean scatter image \n",
    "img, path, filename = pcv.readimage(filename=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d237fd-06d3-4c13-8c88-246338b513e0",
   "metadata": {
    "id": "XW4LtZYIkWRN"
   },
   "outputs": [],
   "source": [
    "# Load your rotated or cropped image into the rgb_img argument to detect the color card.\n",
    "cc_mask = pcv.transform.detect_color_card(rgb_img=img)\n",
    "\n",
    "# We will also print the average chip size and store the values in outputs.observations.\n",
    "print(pcv.outputs.observations['default']['median_color_chip_size']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3265c4-c2a8-42c6-a923-a0b2b7e36986",
   "metadata": {
    "id": "sqmjQ_HvkWRN"
   },
   "outputs": [],
   "source": [
    "# Next, we make a color card matrix. You will not see an output for this step.\n",
    "\n",
    "headers, card_matrix = pcv.transform.get_color_matrix(rgb_img=img, mask=cc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae5ace-a369-4756-97d0-119c69e7563b",
   "metadata": {
    "id": "l2obStF5kWRO"
   },
   "outputs": [],
   "source": [
    "# Define the standard color card matrix, we know what the colors of those chips should be in a \"perfect\" image, so we will correct to those values\n",
    "# Look at where your white chip is in the image to determine which position your card is in (pos)\n",
    "# When using detect_color_card, you will always set pos=3.\n",
    "\n",
    "#pos     = reference value indicating orientation of the color card. The reference\n",
    "       #         is based on the position of the white chip:\n",
    "        #        pos = 0: bottom-left corner\n",
    "        #        pos = 1: bottom-right corner\n",
    "        #        pos = 2: top-right corner\n",
    "        #        pos = 3: top-left corner\n",
    "\n",
    "std_color_matrix = pcv.transform.std_color_matrix (pos=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd335ec-3ed8-4955-a354-a63383d79ca6",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "92231a1601064c09837e97ab5eadc97f",
      "bca99d559bfa4932939547aebd7eda73"
     ]
    },
    "id": "w0n6YO3DkWRO",
    "outputId": "8624acf1-b070-42b7-bebf-efe583a296f2"
   },
   "outputs": [],
   "source": [
    "#Color correct your image to the standard values.\n",
    "#look at the image - does the color look good? \n",
    "# If it looks crazy, you probably don't have the card found well and need to go back to \n",
    "# define the start and spacing for the card.\n",
    "\n",
    "img_cc = pcv.transform.affine_color_correction(img, card_matrix, std_color_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fd0f7-11d4-45bf-9aa6-029886ee647d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cs = pcv.visualize.colorspaces(rgb_img=img_cc, original_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why are they directly extracting the B*?\n",
    "# Inputs:\n",
    "#   rbg_img - original image\n",
    "#   channel - desired colorspace ('l', 'a', or 'b')\n",
    "\n",
    "gray = pcv.rgb2gray_cmyk(rgb_img=img, channel=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   gray_img    = grayscale image created from selected colorspace\n",
    "\n",
    "bin_mask = pcv.threshold.binary(gray_img=gray, threshold=, object_type=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "#   size - maximum size for objects that should be filled in as background (non-plant) pixels\n",
    "fill = pcv.fill(bin_img=bin_mask, size=)\n",
    "#                                      /\\\n",
    "#                                      |\n",
    "#                                 change this value if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flood fill \n",
    "\n",
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "\n",
    "clean_mask = pcv.fill_holes(bin_img=fill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-encyclopedia",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "# Set Region Of Interest \n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img         = RGB or grayscale image for plotting\n",
    "#   x           = x coordinate of the center of ROI \n",
    "#   y           = y coordinate of the center of ROI \n",
    "#   r           = radius of the ROI to get drawn\n",
    "\n",
    "\n",
    "roi = pcv.roi.rectangle(img=img, x=, y=, h=, w=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   mask         = Binary image\n",
    "#   roi          = Region of interest, defined in an upstream step\n",
    "#   roi_type     = 'cutto', 'partial' (for partially inside, default), or\n",
    "#                 'largest' (keep only the largest contour)\n",
    "\n",
    "filtered_mask = pcv.roi.filter(mask=clean_mask, roi=roi, roi_type=\"partial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv.params.text_size = 2\n",
    "pcv.params.text_thickness = 2\n",
    "\n",
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   num_objects = Optional parameter to limit the number of objects that will get annotated.\n",
    "\n",
    "sizes = pcv.visualize.obj_sizes(img=img, mask=filtered_mask, num_objects=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    mask            = mask image\n",
    "#    rois            = (Optional) list of multiple ROIs (from roi.multi or roi.auto_grid)\n",
    "#    roi_type        = (Optional) type of filtering, either partial' (for partially inside, default), \n",
    "#                       cutto' (hard cut at boundary), 'largest' (keep only the largest contour)\n",
    "\n",
    "labeled_mask, num = pcv.create_labels(mask=filtered_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract size traits\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging \n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "        \n",
    "shape_img = pcv.analyze.size(img=img, labeled_mask=labeled_mask, n_labels=num, label=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract color traits from each replicate\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging \n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   colorspaces  = 'all', 'rgb', 'lab', or 'hsv' (default = 'hsv').\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "color_img = pcv.analyze.color(rgb_img=img, labeled_mask=labeled_mask, n_labels=num, label=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out unclassified bean trait data \n",
    "pcv.outputs.save_results(\"unclassified_bean_data.csv\", \"csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV data and train on X traits\n",
    "f2 = \"unclassified_bean_data.csv\"\n",
    "df2 = pd.read_csv(f2)\n",
    "\n",
    "# Filter the traits kept\n",
    "bean_features2 = df2[df2['trait'].isin(['area', 'convex_hull_area', 'solidity',\n",
    "                                     'perimeter', 'width', 'height', 'ellipse_major_axis',\n",
    "                                     'ellipse_minor_axis', 'ellipse_eccentricity',\n",
    "                                     'hue_circular_mean', 'hue_median'])]\n",
    "\n",
    "# Pivot the dataframe from \"long\" format to \"wide\"\n",
    "bean_features_wide2 = pd.pivot(bean_features2, index='sample', columns=\"trait\", values=\"value\")\n",
    "# Cast to numpy array \n",
    "np_features2 = bean_features_wide2.to_numpy()\n",
    "\n",
    "# Extrat list of traits\n",
    "trait_list2 = bean_features_wide2.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then predict instead of forest.fit \n",
    "X_class = np_features2\n",
    "\n",
    "classifier = forest.predict(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the predictions\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the predictions with PlantCV data that marks the location of each bean in the image\n",
    "classes = pd.DataFrame({\"sample\": bean_features_wide2.index.tolist(), \"class\": classifier.tolist()})\n",
    "classes = classes.merge(df2.loc[(df2[\"trait\"] == \"center_of_mass\") & (df2[\"label\"] == \"x\")])\n",
    "classes.drop([\"trait\", \"label\"], axis=1, inplace=True)\n",
    "classes.rename({\"value\": \"cmx\"}, inplace=True, axis=1)\n",
    "classes = classes.merge(df2.loc[(df2[\"trait\"] == \"center_of_mass\") & (df2[\"label\"] == \"y\")])\n",
    "classes.drop([\"trait\", \"label\"], axis=1, inplace=True)\n",
    "classes.rename({\"value\": \"cmy\"}, inplace=True, axis=1)\n",
    "\n",
    "# Label the bean class next to each bean on the image\n",
    "pcv.params.text_size = 1\n",
    "pcv.params.text_thickness = 2\n",
    "\n",
    "outimg = img.copy()\n",
    "for index, row in classes.iterrows():\n",
    "    cv2.putText(img=outimg, text=row[\"class\"], org=(int(row[\"cmx\"]), int(row[\"cmy\"])),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=pcv.params.text_size,\n",
    "                color=(255, 255, 255), thickness=pcv.params.text_thickness)\n",
    "pcv.plot_image(outimg)\n",
    "pcv.print_image(outimg, filename=\"./legume_guess.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a table of the probability each bean belongs to each category/class\n",
    "print(forest.classes_)\n",
    "forest.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-stuart",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PlantCV)",
   "language": "python",
   "name": "plantcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
