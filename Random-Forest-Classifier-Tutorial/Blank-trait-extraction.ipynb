{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developed-lying",
   "metadata": {
    "id": "developed-lying"
   },
   "source": [
    "<span style=\"color:maroon\">\n",
    "\n",
    "# Extract traits from legume images\n",
    "    \n",
    "## =====================================================================\n",
    "\n",
    "## Legumes Example\n",
    "## =====================================================================\n",
    "\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-lightweight",
   "metadata": {
    "id": "graphic-lightweight"
   },
   "source": [
    "We want to extract traits about different legumes. We will measure these traits using image analysis and save data into a CSV for Machine Learning in a later activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-stadium",
   "metadata": {
    "id": "brazilian-stadium"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "Headers in purple will indicate a step that **might** need adjusting to parameterize the workflow to your particular image.\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-figure",
   "metadata": {
    "id": "prospective-figure"
   },
   "source": [
    "## June 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-breakdown",
   "metadata": {
    "id": "royal-breakdown",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib widget\n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-interference",
   "metadata": {
    "id": "strange-interference"
   },
   "outputs": [],
   "source": [
    "# Print out the version of PlantCV being used by the Jupyter kernel\n",
    "pcv.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-specialist",
   "metadata": {
    "id": "african-specialist"
   },
   "source": [
    "# Initialize workflow inputs & outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-theta",
   "metadata": {
    "id": "accomplished-theta"
   },
   "outputs": [],
   "source": [
    "# Set debugging parameters\n",
    "pcv.params.debug = \"plot\"\n",
    "pcv.params.text_size = 25\n",
    "pcv.params.text_thickness = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-aging",
   "metadata": {
    "id": "prospective-aging"
   },
   "source": [
    "\n",
    "What exactly is a filepath? In general, a path is a string of characters which specifies a unique location in a directory or page hierarchy. For file systems, each level in the hierarchy is a directory.\n",
    "\n",
    "`/home/user/python/test.py`\n",
    "\n",
    "In this file path, the test.py file is inside the python directory. The python directory is a subdirectory of the user directory, which is a subdirectory of the home directory. Absolute file paths specify the location of a file from the root directory in the file system structure. They are also called “full file paths” or “full paths.” In Linux, the tilde (~) is commonly used to represent a user’s home directory in a file path. Relative file paths specify the location of a file in the same folder or on the same server. In other words, a relative file path specifies a location of a file that is relative to the current directory.\n",
    "\n",
    "\n",
    "(https://www.codecademy.com/resources/docs/general/file-paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-fifteen",
   "metadata": {
    "id": "animated-fifteen"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "\n",
    "## Read in the image\n",
    "    \n",
    "File name and extension are case sensitive.\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-salmon",
   "metadata": {
    "id": "wooden-salmon"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "\n",
    "# Inputs:\n",
    "#   filename - Image file to be read in\n",
    "#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "\n",
    "img, imgpath, imgname = pcv.readimage(filename=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-photography",
   "metadata": {
    "id": "robust-photography"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "    \n",
    "# Rename your seed\n",
    "\n",
    "### Use CamelCase and\n",
    "## avoid spaces or underscores !!!\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-bobby",
   "metadata": {
    "id": "absent-bobby"
   },
   "outputs": [],
   "source": [
    "seed_name = 'bean_name' # Change this to the name of the bean you imaged!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cd545-9008-4c4a-9745-df4585e62bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5c4ab-6103-4616-abe8-caca3c747cf6",
   "metadata": {},
   "source": [
    "## Detecting and Calibrating Colors with Color Cards/Color Checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e2aca-ffff-4890-b7cb-4716ac5f0d6c",
   "metadata": {
    "id": "XW4LtZYIkWRN"
   },
   "outputs": [],
   "source": [
    "# Load your rotated or cropped image into the rgb_img argument to detect the color card.\n",
    "cc_mask = pcv.transform.detect_color_card(rgb_img=img)\n",
    "\n",
    "# We will also print the average chip size and store the values in outputs.observations.\n",
    "print(pcv.outputs.observations['default']['median_color_chip_size']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf603a1-d013-4c27-b8b2-7c02568ca643",
   "metadata": {
    "id": "sqmjQ_HvkWRN"
   },
   "outputs": [],
   "source": [
    "# Next, we make a color card matrix. You will not see an output for this step.\n",
    "\n",
    "headers, card_matrix = pcv.transform.get_color_matrix(rgb_img=img, mask=cc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bec02-c46a-4502-a4d4-0d3cf38b3143",
   "metadata": {
    "id": "l2obStF5kWRO"
   },
   "outputs": [],
   "source": [
    "# Define the standard color card matrix, we know what the colors of those chips should be in a \"perfect\" image, so we will correct to those values\n",
    "# Look at where your white chip is in the image to determine which position your card is in (pos)\n",
    "# When using detect_color_card, you will always set pos=3.\n",
    "\n",
    "#pos     = reference value indicating orientation of the color card. The reference\n",
    "       #         is based on the position of the white chip:\n",
    "        #        pos = 0: bottom-left corner\n",
    "        #        pos = 1: bottom-right corner\n",
    "        #        pos = 2: top-right corner\n",
    "        #        pos = 3: top-left corner\n",
    "\n",
    "std_color_matrix = pcv.transform.std_color_matrix (pos=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217e98a-4040-4a35-9bf6-bfa5090072ad",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "92231a1601064c09837e97ab5eadc97f",
      "bca99d559bfa4932939547aebd7eda73"
     ]
    },
    "id": "w0n6YO3DkWRO",
    "outputId": "8624acf1-b070-42b7-bebf-efe583a296f2"
   },
   "outputs": [],
   "source": [
    "#Color correct your image to the standard values.\n",
    "#look at the image - does the color look good? \n",
    "# If it looks crazy, you probably don't have the card found well and need to go back to \n",
    "# define the start and spacing for the card.\n",
    "\n",
    "img_cc = pcv.transform.affine_color_correction(img, card_matrix, std_color_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-cross",
   "metadata": {
    "id": "appropriate-cross",
    "tags": []
   },
   "source": [
    "## Visualize Colorspaces\n",
    "The visualization tool converts the color image into HSV and LAB colorspaces and displays the grayscale channels in a matrix so that they can be visualized simultaneously. The idea is to select a channel that maximizes the difference between the plant and the background pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-office",
   "metadata": {
    "id": "inclusive-office",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   rbg_img      = original image\n",
    "#   original_img = whether to include the original RGB images in the display: True (default) or False\n",
    "\n",
    "all_c = pcv.visualize.colorspaces(rgb_img=img_cc, original_img=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-hearts",
   "metadata": {
    "id": "played-hearts",
    "tags": []
   },
   "source": [
    "## Convert the color image to grayscale\n",
    "Converts the input color image into the LAB colorspace and returns the B (blue-yellow) channel as a grayscale image. We have already tested ever type of bean and found that \"b\" channel did well (since we chose a blue background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-trading",
   "metadata": {
    "id": "official-trading"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   rbg_img - original image\n",
    "#   channel - desired colorspace ('l', 'a', or 'b')\n",
    "\n",
    "gray = pcv.rgb2gray_(rgb_img=img_cc, channel=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-cooperative",
   "metadata": {
    "id": "superb-cooperative"
   },
   "source": [
    "# Visualize the distribution of grayscale values\n",
    "A histogram can be used to visualize the distribution of values in an image. The histogram can aid in the selection of a threshold value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-muscle",
   "metadata": {
    "id": "standard-muscle"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   bins        = 100 (default) or number of desired number of evenly spaced bins\n",
    "#   lower-bound = None (default) or minimum value on x-axis\n",
    "#   upper-bound = None (default) or maximum value on x-axis\n",
    "#   title       = None (default) or custom plot title\n",
    "#   hist_data   = False (default) or True (if frequency distribution data is desired)\n",
    "\n",
    "hist = pcv.visualize.histogram(img=gray, bins=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-paper",
   "metadata": {
    "id": "infrared-paper"
   },
   "source": [
    "## Threshold the grayscale image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4fd48-0fbd-4ecd-9d4b-3491b6227b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_mask = pcv.threshold.binary(gray_img=gray, threshold= , object_type=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649cbaf8-efd7-4eac-a530-9b40ab16f64e",
   "metadata": {
    "id": "choice-communications"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "\n",
    "## Remove small background noise\n",
    "    \n",
    "_Thresholding mostly labeled plant pixels white but also labeled small regions of the background white. The fill function removes \"salt\" noise from the background by filtering white regions by size. The resolution of the image will factor into the average object sizes in your images so this step might require adjustment._\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-builder",
   "metadata": {
    "id": "average-builder"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "#   size - maximum size for objects that should be filled in as background (non-plant) pixels\n",
    "\n",
    "fill = pcv.fill(bin_img=bin_mask, size=)\n",
    "#                                       /\\\n",
    "#                                       |\n",
    "#                                 change this value (maybe, mostly depends on img size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8e039-774d-4a67-b643-94005346f3b0",
   "metadata": {
    "id": "quality-friend"
   },
   "source": [
    "## Flood fill \"pepper\" noise\n",
    "\n",
    "The `pcv.fill_holes` function does a flood fill of any missing portions that are surrounded by white pixels. This will address the glare in the center of each bean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-remark",
   "metadata": {
    "id": "therapeutic-remark"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "\n",
    "clean_mask = pcv.fill_holes(bin_img=fill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-register",
   "metadata": {
    "id": "polish-register"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "    \n",
    "# Define Region of Interest    \n",
    "    \n",
    "_Highly likely that this step will need the parameters adjusted to each image_\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-scheduling",
   "metadata": {
    "id": "obvious-scheduling"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img         = RGB or grayscale image for plotting\n",
    "#   x           = x coordinate of the center of ROI\n",
    "#   y           = y coordinate of the center of ROI\n",
    "#   r           = radium of the ROI to get drawn\n",
    "\n",
    "\n",
    "roi = pcv.roi.rectangle(img=img_cc, x=, y=, h=, w=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-certificate",
   "metadata": {
    "id": "fifth-certificate"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   mask         = Binary image\n",
    "#   roi          = Region of interest, defined in an upstream step\n",
    "#   roi_type     = 'cutto', 'partial' (for partially inside, default), or\n",
    "#                  'largest' (keep only the largest contour)\n",
    "\n",
    "filtered_mask = pcv.roi.filter(mask=clean_mask, roi=roi, roi_type=\"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-architect",
   "metadata": {
    "id": "amazing-architect"
   },
   "source": [
    "## Investigate object sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-corner",
   "metadata": {
    "id": "proved-corner"
   },
   "outputs": [],
   "source": [
    "pcv.params.text_size = 1\n",
    "pcv.params.text_thickness = 2\n",
    "\n",
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   num_objects = Optional parameter to limit the number of objects that will get annotated (default = 100).\n",
    "\n",
    "sizes = pcv.visualize.obj_sizes(img=img, mask=filtered_mask, num_objects=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-phrase",
   "metadata": {
    "id": "fabulous-phrase"
   },
   "source": [
    "Salt & pepper noise are small white/black pixels, respectively, in the binary mask. In this example image, the flash creates a glare that makes the centers of the beans get excluded during segmentation, but we can recover these pixels with some clean up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-memorabilia",
   "metadata": {
    "id": "liberal-memorabilia"
   },
   "source": [
    "## Create labeled mask\n",
    "We want to extract traits from each bean replicate, so we need to create a mask that has unique pixel values for each identified object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-camping",
   "metadata": {
    "id": "horizontal-camping"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    mask            = mask image\n",
    "#    rois            = (Optional) list of multiple ROIs (from roi.multi or roi.auto_grid)\n",
    "#    roi_type        = (Optional)''partial' (for partially inside, default), cutto' (hard cut at boundary),\n",
    "#                      'largest' (keep only the largest contour)\n",
    "\n",
    "labeled_mask, num = pcv.create_labels(mask=filtered_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-customs",
   "metadata": {
    "id": "alive-customs"
   },
   "source": [
    "## Extract seed shape and color traits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-summit",
   "metadata": {
    "id": "formal-summit"
   },
   "outputs": [],
   "source": [
    "# Extract size traits\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "shape_img = pcv.analyze.size(img=img_cc, labeled_mask=labeled_mask, n_labels=num, label=seed_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-press",
   "metadata": {
    "id": "characteristic-press"
   },
   "source": [
    "# Extract color data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-firmware",
   "metadata": {
    "id": "romance-firmware"
   },
   "outputs": [],
   "source": [
    "# Extract color traits from each replicate\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   colorspaces  = 'all', 'rgb', 'lab', or 'hsv' (default = 'hsv')\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "color_img = pcv.analyze.color(rgb_img=img_cc, labeled_mask=labeled_mask, n_labels=num, colorspaces=\"hsv\",\n",
    "                              label=seed_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-creek",
   "metadata": {
    "id": "capital-creek"
   },
   "outputs": [],
   "source": [
    "# Look at what has been stored into the Outputs class as observations from our workflow\n",
    "# Pretty unreadable due to the heirarchical format, but we just extracted TONS of raw phenotype data\n",
    "\n",
    "#pcv.outputs.observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-error",
   "metadata": {
    "id": "scenic-error"
   },
   "source": [
    "# How large is the first bean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-secretary",
   "metadata": {
    "id": "british-secretary"
   },
   "outputs": [],
   "source": [
    "# Index the dictionary of traits to look at the area for one replicate\n",
    "\n",
    "indexing_name = f\"{seed_name}_1\"\n",
    "pcv.outputs.observations[indexing_name]['area']['value']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-syndicate",
   "metadata": {
    "id": "vertical-syndicate"
   },
   "source": [
    "## Save results\n",
    "\n",
    "During analysis, measurements are stored in the background in the outputs recorder.\n",
    "\n",
    "This example includes image analysis for 'area', 'convex_hull_area', 'solidity', 'perimeter', 'width', 'height', 'longest_path', 'center_of_mass, 'convex_hull_vertices', 'object_in_frame', 'ellipse_center', 'ellipse_major_axis', 'ellipse_minor_axis', 'ellipse_angle', 'ellipse_eccentricity' using `pcv.analyze.size` and color analysis using `pcv.analyze.color`.\n",
    "\n",
    "Here, results are saved to a CSV file. Filename will update with bean name set at top of this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-height",
   "metadata": {
    "id": "specific-height"
   },
   "outputs": [],
   "source": [
    "csv_filename = f\"{seed_name}_csv.csv\"\n",
    "pcv.outputs.save_results(csv_filename, \"csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-viking",
   "metadata": {
    "id": "gorgeous-viking"
   },
   "source": [
    "Now we can go look for the CSV file that we just saved out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-aurora",
   "metadata": {
    "id": "numerical-aurora"
   },
   "source": [
    "<span style=\"color:maroon\">\n",
    "\n",
    "# Duplicate this workflow\n",
    "\n",
    "_Click the (File) tab in the top left corner. (Make a copy ... ) And rename the new jupyter notebook with your next bean type._\n",
    "    \n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (PlantCV)",
   "language": "python",
   "name": "plantcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
